# MovieLens-MCRS

Collaborative movie recommendation system that compares classical and neural
approaches on the MovieLens dataset. The project walks from exploratory data
analysis and preprocessing through baseline models (Surprise SVD, Spark ALS)
up to deep-learning recommenders (Neural Collaborative Filtering and Denoising
Autoencoder), and finishes with a Streamlit dashboard for interactive
exploration.

## Key Features
- Exploratory data analysis to understand user/item distributions and rating
  sparsity.
- Reusable preprocessing pipeline that produces consistent train/valid/test
  splits and enriched metadata.
- Multiple recommendation baselines:
  - Surprise SVD / SVD++ for matrix factorisation.
  - Spark ALS for large-scale collaborative filtering.
  - Neural Collaborative Filtering (NCF) MLP model.
  - Denoising Autoencoder for implicit signal reconstruction.
- Unified evaluation utilities reporting RMSE/MAE together with Precision,
  Recall, and nDCG at K.
- `dashboard/app.py` Streamlit app that serves recommendations from the trained
  NCF model and visualises dataset insights.

## Repository Layout
- `data/raw/` — Raw MovieLens CSVs (`ratings.csv`, `movies.csv`, `tags.csv`,
  `links.csv`) downloaded from GroupLens.
- `data/processed/` — Cleaned splits (`ratings_train|valid|test.csv`) and
  enriched metadata (`movies_enriched.csv`) generated by
  `02_preprocessing.ipynb`.
- `models/` — Saved PyTorch checkpoints (`ncf_best.pth`, `autoencoder_best.pth`)
  used by the dashboard and evaluation scripts.
- `notebooks/` — Jupyter workflow from EDA to evaluation. Each notebook is
  numbered in execution order.
- `reports/` — Summary CSVs, plots, and `results.csv` containing model metrics.
- `src/` — Reusable Python modules (data loading, SVD utilities, NCF/AE models,
  evaluation helpers).
- `dashboard/` — Streamlit application for demoing recommendations.
- `environment.yml` — Conda environment specification for the full toolchain.

## Environment Setup
1. Install [conda](https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html).
2. Create and activate the project environment:
   ```bash
   conda env create -f environment.yml
   conda activate movielens-mcrs
   ```
   The environment ships with PySpark, PyTorch, Surprise, and Streamlit. Java
   17 is included via `openjdk`, so no external Spark install is required.
3. (Optional) Register the environment as a Jupyter kernel:
   ```bash
   python -m ipykernel install --user --name movielens-mcrs
   ```

## Data
The project uses the [MovieLens 100K dataset](https://grouplens.org/datasets/movielens/100k/).

1. Download from [https://grouplens.org/datasets/movielens/100k/](https://grouplens.org/datasets/movielens/100k/).
2. Unzip the archive and place the CSVs under:
   ```
   MovieLens-MCRS/data/raw/
     ├─ ratings.csv
     ├─ movies.csv
     ├─ tags.csv
     └─ links.csv
   ```
3. (Optional) Run `02_preprocessing.ipynb` to regenerate the processed splits
   and reports. Pre-generated processed files are already included.

> The notebooks assume they are executed from the repository root so that
> relative paths (`data/raw/...`) resolve correctly. Notebook `03_baseline_ALS_PySpark.ipynb`
> leverages PySpark; ensure the environment is activated before launching.

## Workflow & Notebooks
| Notebook / Script | Purpose | Key Outputs |
| --- | --- | --- |
| `01_eda.ipynb` | Exploratory analysis of ratings, movies, and user behaviour. | `reports/eda_summary.csv`, exploratory plots under `reports/figures/`. |
| `02_preprocessing.ipynb` | Cleans raw data, builds time-aware train/valid/test splits, enriches movies with multi-hot genres. | `data/processed/ratings_*.csv`, `data/processed/movies_enriched.csv`. |
| `03_baseline_SVD.ipynb` | Surprise SVD/SVD++ baselines with grid search. | Cross-validated RMSE/MAE, exemplar recommendations. |
| `03_baseline_ALS_PySpark.ipynb` | Spark ALS matrix factorisation baseline with parameter tuning. | Serialized Spark model under `models/als_movielens` and validation predictions in `outputs/`. |
| `04_MLP_NCF.ipynb` | Trains a neural collaborative filtering model (MLP) using PyTorch. | `models/ncf_best.pth`, training curves. |
| `05_AutoEncoder.ipynb` | Builds a denoising autoencoder over dense user-item matrices. | `models/autoencoder_best.pth`. |
| `06_evaluation.ipynb` | Aggregates regression and ranking metrics using `src/evaluation.py`. | `reports/results.csv`, `reports/top_movies.csv`, `reports/genre_stats.csv`, `reports/active_users.csv`. |
| `dashboard/app.py` | Streamlit application showcasing metrics and top-k recommendations. | Interactive UI (run via `streamlit run dashboard/app.py`). |

## Model Performance
Aggregated metrics from `reports/results.csv` (test split, `k=10`):

| Model | RMSE ↓ | MAE ↓ | Precision@10 ↑ | Recall@10 ↑ | nDCG@10 ↑ |
| --- | --- | --- | --- | --- | --- |
| SVD | 0.867 | 0.662 | 0.037 | 0.044 | 0.050 |
| NCF | 0.886 | 1.385 | 0.029 | 0.038 | 0.042 |
| AutoEncoder | 1.716 | 1.363 | 0.039 | 0.052 | 0.056 |

Additional metrics for classical baselines are discussed inside the corresponding
notebooks. Use `06_evaluation.ipynb` to recompute the comparison after retraining.

## Running the Streamlit Dashboard
1. Ensure the conda environment is active and the processed data/model
   checkpoints are available (generated by notebooks or provided in the repo).
2. Launch the app from the project root:
   ```bash
   streamlit run dashboard/app.py
   ```
3. Use the sidebar to select a user and inspect personalised top-k
   recommendations, recent history, and dataset summaries.

## Source Utilities
- `src/data_loader.py`: pandas-based loaders, cold-start filtering, genre
  encoding, and chronological splitting helpers.
- `src/svd_model.py`: Surprise SVD/SVD++ training, evaluation, and top-k
  recommendation utilities.
- `src/ncf_model.py`: PyTorch NCF model architecture plus encoding helpers.
- `src/autoencoder_model.py`: Denoising autoencoder modules for dense user-item
  reconstruction.
- `src/evaluation.py`: Shared regression and ranking metric calculators as well
  as top-k recommendation wrappers for the neural models.

## Reproducing Results
1. Run `02_preprocessing.ipynb` to regenerate splits (optional if using the
   provided processed data).
2. Execute the baseline notebooks (`03_*`) to train collaborative-filtering
   models.
3. Train neural models with `04_MLP_NCF.ipynb` and `05_AutoEncoder.ipynb`.
4. Summarise everything in `06_evaluation.ipynb` to update
   `reports/results.csv`.
5. Refresh the dashboard to visualise the newest metrics and recommendations.

## Acknowledgements
- GroupLens Research for the publicly available MovieLens dataset.
- Surprise, PySpark, and PyTorch teams for the open-source recommender tooling.
